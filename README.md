# Sparkify ETL

Welcome to Sparkify ETL!!

## About this Project

_"The objective of this project is to exercise ETL and Data-warehouse concepts as part of my [Data Engineer Nanodegree](https://www.udacity.com/course/data-engineer-nanodegree--nd027?gclid=CjwKCAjwrranBhAEEiwAzbhNtX2u0Cgqf42F_UgP68QhJ381lLzPJXH_MUBvquNKyhMGQZfr34Lh4hoCJKoQAvD_BwE&utm_campaign=19167921312_c_individuals&utm_keyword=udacity%20data%20engineering_e&utm_medium=ads_r&utm_source=gsem_brand&utm_term=143524475719)"._ 
The project consists of an ETL pipeline to build a Data-warehouse in AWS following the schemas bellow:

![](github/star-schema.jpg)

## Why?

This project is part of my personal portfolio, so, I'll be happy if you could provide me any feedback about the project, code, structure or anything that you can report that could make me a better developer!

Email-me: harrisonhenrisn@gmail.com

Connect with me at [LinkedIn](https://linkedin.com/in/harrison-henri-dos-santos-nascimento

## Local installation and configuration

To install and run the project locally, first, add a .env file (based on the .env.example)!

1. Install the python (minimum version of the project.toml at least)

2. Install the dependencies with:

```=sh
pip install poetry
python -m venv venv
poetry install
```

3. Run with:

```=sh
jupyter notebook
```

## Built with

<div>
<img align="left" alt="Redshift" width="60px" style="margin-left:1em; margin-top:10px" src="https://upload.wikimedia.org/wikipedia/commons/7/73/Amazon-Redshift-Logo.svg" />
<img align="left" alt="S3" width="90px" style="margin-left:1em" src="https://cdn.iconscout.com/icon/free/png-512/free-amazon-s3-2968702-2464706.png?f=avif&w=512" />
<br /><br /><br /><br />
</div>
